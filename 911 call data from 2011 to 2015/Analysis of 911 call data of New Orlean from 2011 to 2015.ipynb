{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2011 = pd.read_csv('Calls_for_Service_2011.csv')\n",
    "data_2012 = pd.read_csv('Calls_for_Service_2012.csv')\n",
    "data_2013 = pd.read_csv('Calls_for_Service_2013.csv')\n",
    "data_2014 = pd.read_csv('Calls_for_Service_2014.csv')\n",
    "data_2015 = pd.read_csv('Calls_for_Service_2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data_2011, data_2012, data_2013, data_2014, data_2015], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOPD_Item</th>\n",
       "      <th>Type_</th>\n",
       "      <th>TypeText</th>\n",
       "      <th>Priority</th>\n",
       "      <th>MapX</th>\n",
       "      <th>MapY</th>\n",
       "      <th>TimeCreate</th>\n",
       "      <th>TimeDispatch</th>\n",
       "      <th>TimeArrive</th>\n",
       "      <th>TimeClosed</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>DispositionText</th>\n",
       "      <th>BLOCK_ADDRESS</th>\n",
       "      <th>Zip</th>\n",
       "      <th>PoliceDistrict</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> A0000111</td>\n",
       "      <td> 17M</td>\n",
       "      <td> MUNICIPAL  ATTTACHME</td>\n",
       "      <td> 1F</td>\n",
       "      <td> 3673089</td>\n",
       "      <td> 533629</td>\n",
       "      <td> 01/01/2011 12:00:02 AM</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 01/01/2011 12:00:03 AM</td>\n",
       "      <td> NAT</td>\n",
       "      <td> NECESSARY ACTION TAKEN</td>\n",
       "      <td> 007XX S Dupre St</td>\n",
       "      <td> 70119</td>\n",
       "      <td> 1</td>\n",
       "      <td> (29.961547427694992, -90.09455728362126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> A0000211</td>\n",
       "      <td> 17M</td>\n",
       "      <td> MUNICIPAL  ATTTACHME</td>\n",
       "      <td> 1F</td>\n",
       "      <td> 3673089</td>\n",
       "      <td> 533629</td>\n",
       "      <td> 01/01/2011 12:00:02 AM</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 01/01/2011 12:00:04 AM</td>\n",
       "      <td> NAT</td>\n",
       "      <td> NECESSARY ACTION TAKEN</td>\n",
       "      <td> 007XX S Dupre St</td>\n",
       "      <td> 70119</td>\n",
       "      <td> 1</td>\n",
       "      <td> (29.961547427694992, -90.09455728362126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> A0000311</td>\n",
       "      <td> 17M</td>\n",
       "      <td> MUNICIPAL  ATTTACHME</td>\n",
       "      <td> 1F</td>\n",
       "      <td> 3673089</td>\n",
       "      <td> 533629</td>\n",
       "      <td> 01/01/2011 12:00:02 AM</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 01/01/2011 12:00:04 AM</td>\n",
       "      <td> NAT</td>\n",
       "      <td> NECESSARY ACTION TAKEN</td>\n",
       "      <td> 007XX S Dupre St</td>\n",
       "      <td> 70119</td>\n",
       "      <td> 1</td>\n",
       "      <td> (29.961547427694992, -90.09455728362126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> A0000411</td>\n",
       "      <td> 17M</td>\n",
       "      <td> MUNICIPAL  ATTTACHME</td>\n",
       "      <td> 1F</td>\n",
       "      <td> 3673089</td>\n",
       "      <td> 533629</td>\n",
       "      <td> 01/01/2011 12:00:02 AM</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 01/01/2011 12:00:04 AM</td>\n",
       "      <td> NAT</td>\n",
       "      <td> NECESSARY ACTION TAKEN</td>\n",
       "      <td> 007XX S Dupre St</td>\n",
       "      <td> 70119</td>\n",
       "      <td> 1</td>\n",
       "      <td> (29.961547427694992, -90.09455728362126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> A0000511</td>\n",
       "      <td> 17M</td>\n",
       "      <td> MUNICIPAL  ATTTACHME</td>\n",
       "      <td> 1F</td>\n",
       "      <td> 3673089</td>\n",
       "      <td> 533629</td>\n",
       "      <td> 01/01/2011 12:00:02 AM</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 01/01/2011 12:00:05 AM</td>\n",
       "      <td> NAT</td>\n",
       "      <td> NECESSARY ACTION TAKEN</td>\n",
       "      <td> 007XX S Dupre St</td>\n",
       "      <td> 70119</td>\n",
       "      <td> 1</td>\n",
       "      <td> (29.961547427694992, -90.09455728362126)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NOPD_Item Type_              TypeText Priority     MapX    MapY  \\\n",
       "0  A0000111   17M  MUNICIPAL  ATTTACHME       1F  3673089  533629   \n",
       "1  A0000211   17M  MUNICIPAL  ATTTACHME       1F  3673089  533629   \n",
       "2  A0000311   17M  MUNICIPAL  ATTTACHME       1F  3673089  533629   \n",
       "3  A0000411   17M  MUNICIPAL  ATTTACHME       1F  3673089  533629   \n",
       "4  A0000511   17M  MUNICIPAL  ATTTACHME       1F  3673089  533629   \n",
       "\n",
       "               TimeCreate TimeDispatch TimeArrive              TimeClosed  \\\n",
       "0  01/01/2011 12:00:02 AM          NaN        NaN  01/01/2011 12:00:03 AM   \n",
       "1  01/01/2011 12:00:02 AM          NaN        NaN  01/01/2011 12:00:04 AM   \n",
       "2  01/01/2011 12:00:02 AM          NaN        NaN  01/01/2011 12:00:04 AM   \n",
       "3  01/01/2011 12:00:02 AM          NaN        NaN  01/01/2011 12:00:04 AM   \n",
       "4  01/01/2011 12:00:02 AM          NaN        NaN  01/01/2011 12:00:05 AM   \n",
       "\n",
       "  Disposition         DispositionText     BLOCK_ADDRESS    Zip  \\\n",
       "0         NAT  NECESSARY ACTION TAKEN  007XX S Dupre St  70119   \n",
       "1         NAT  NECESSARY ACTION TAKEN  007XX S Dupre St  70119   \n",
       "2         NAT  NECESSARY ACTION TAKEN  007XX S Dupre St  70119   \n",
       "3         NAT  NECESSARY ACTION TAKEN  007XX S Dupre St  70119   \n",
       "4         NAT  NECESSARY ACTION TAKEN  007XX S Dupre St  70119   \n",
       "\n",
       "   PoliceDistrict                                  Location  \n",
       "0               1  (29.961547427694992, -90.09455728362126)  \n",
       "1               1  (29.961547427694992, -90.09455728362126)  \n",
       "2               1  (29.961547427694992, -90.09455728362126)  \n",
       "3               1  (29.961547427694992, -90.09455728362126)  \n",
       "4               1  (29.961547427694992, -90.09455728362126)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: What fraction of calls are of the most common type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2453953699658411"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(data['Type_'].value_counts().max())/data['Type_'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Some calls result in an officer being dispatched to the scene, and some log an arrival time. What is the median response time (dispatch to arrival), in seconds, considering only valid (i.e. non-negative) times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_time = data.dropna(subset = ['TimeDispatch', 'TimeArrive'])#drop data without time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "respond_time = pd.to_datetime(data_with_time['TimeArrive'])-pd.to_datetime(data_with_time['TimeDispatch'])#calculate the time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingyan/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data_with_time['respond_time']= respond_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_time =  data_with_time[data_with_time['respond_time'] >= 0]#drop the data with negative respond time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475.457581"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_time = data_with_time['respond_time'].mean().total_seconds()\n",
    "average_time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Work out the average (mean) response time in each district. What is the difference between the average response times of the districts with the longest and shortest times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "group1= data_with_time['respond_time'].groupby(data_with_time['PoliceDistrict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoliceDistrict\n",
       "0                00:06:43.759710\n",
       "1                00:06:37.465449\n",
       "2                00:08:31.211433\n",
       "3                00:08:25.103193\n",
       "4                00:08:52.475356\n",
       "5                00:07:23.965941\n",
       "6                00:06:56.191877\n",
       "7                00:09:47.512741\n",
       "8                00:07:17.151297\n",
       "Name: respond_time, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_time = group1.sum()/group1.count() ##somehow the .mean() does not work on timedelta\n",
    "mean_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190.04729200000003"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_time.max().total_seconds()-mean_time.min().total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: We can define surprising event types as those that occur more often in a district than they do over the whole city. What is the largest ratio of the conditional probability of an event type given a district to the unconditional probably of that event type? Consider only events types which have more than 100 events. Note that some events have their locations anonymized and are reported as being in district \"0\". These should be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_district = data[data['PoliceDistrict']!= 0] # discard data in district 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_count = data_with_district['Type_'].value_counts() # count 'Type_' in the whole city\n",
    "type_count = type_count[type_count >= 100] # discard event type that less than 100\n",
    "type_probability = type_count/type_count.sum() # calculate the event probability for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probability_df = pd.DataFrame(type_probability, columns = ['total_probability']) #make it a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group2 = data_with_district['Type_'].groupby(data_with_time['PoliceDistrict']) #group the \"Type_\" data by districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate the probability of each event in a district and merge them with the probability_df \n",
    "for i, group in group2:\n",
    "    type_count = group.value_counts()\n",
    "    probability = type_count/type_count.sum()\n",
    "    count_df = pd.DataFrame(probability, columns = [int(i)])\n",
    "    probability_df = probability_df.join(count_df, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_probability    1.000000\n",
       "1                    2.256177\n",
       "2                    2.006965\n",
       "3                    2.332470\n",
       "4                    2.613202\n",
       "5                    2.695849\n",
       "6                    2.462182\n",
       "7                    3.597843\n",
       "8                    5.663850\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to quantify the ratio conditional probability of an event type given a district to the unconditional \n",
    "probability_df = probability_df.div(probability_df['total_probability'], axis = 0)\n",
    "probability_df.max() # find the max ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Find the call type that displayed the largest percentage decrease in volume between 2011 and 2015. What is the fraction of the 2011 volume that this decrease represents? The answer should be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I'd work on the individule dataframe from each year. I count call type from each year and make them a dataframe\n",
    "dfs = [data_2011, data_2012, data_2013, data_2014, data_2015]\n",
    "def count_type(dfs, type_df):\n",
    "    for i in range(len(dfs)):\n",
    "        type_count1 = dfs[i]['Type_'].value_counts()\n",
    "        type_df1 = pd.DataFrame(type_count1, columns = [2011+i]) \n",
    "        type_df = type_df.join(type_df1, how = 'left')\n",
    "    return type_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type_count = data['Type_'].value_counts()\n",
    "type_df = pd.DataFrame(type_count, columns = ['total_count']) #use value_count from all data as a reference column\n",
    "type_count_df = count_type(dfs, type_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99444444444444446"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the largest percentage decrease in volume between 2011 and 2015\n",
    "decrease = (type_count_df[2011]- type_count_df[2015])/type_count_df[2011]\n",
    "decrease.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: The disposition represents the action that was taken to address the serivce call. Consider how the disposition of calls changes with the hour of the record's creation time. Find the disposition whose fraction of that hour's disposition varies the most over a typical day. What is its variation (maximum fraction minus minimum fraction)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_disposition_time = data[['Disposition', 'TimeCreate']].dropna() # delete all data contains na in 'Disposition', 'TimeCreate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times = pd.to_datetime(data_disposition_time['TimeCreate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_disposition_time['time'] = times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hour= times.apply(lambda x: x.hour) # get the hour information in each timedata\n",
    "data_disposition_time['hour']= hour #add the 'hour' column to the data_disposition_time dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group3 = data_disposition_time['Disposition'].groupby(data_disposition_time['hour']) #group the Disposition type by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dis_count = data_disposition_time['Disposition'].value_counts() #calculate the overall disposition ratio as a reference\n",
    "count_all = dis_count/dis_count.sum()\n",
    "dis_day_df = pd.DataFrame(count_all, columns = ['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, group in group3:\n",
    "    dis_count = group.value_counts()\n",
    "    dis_count = dis_count/dis_count.sum()\n",
    "    count_df = pd.DataFrame(dis_count, columns = [i])\n",
    "    dis_day_df = dis_day_df.join(count_df, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del dis_day_df['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variations = dis_day_df.max(axis=1)-dis_day_df.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18808946562536122"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variations.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: We can use the call locations to estimate the areas of the police districts. Represent each as an ellipse with semi-axes given by a single standard deviation of the longitude and latitude. What is the area, in square kilometers, of the largest district measured in this manner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the location data is a string. So first step is to transfer it into float data \n",
    "def clean_location(location_data):\n",
    "    location_data = location_data.strip('(').strip(')').split(',')\n",
    "    lat = float(location_data[0])\n",
    "    lon = float(location_data[1])\n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get ride of missing data, and data in district one\n",
    "data_with_location = data[['Location', 'PoliceDistrict']].dropna()\n",
    "data_with_location = data_with_location[data_with_location['PoliceDistrict']!= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_location['Location'] = data_with_location['Location'].apply(lambda x: clean_location(x))# get the location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations = pd.DataFrame(data_with_location['Location'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations.columns = ['lat', 'lon'] #change name of locations columns\n",
    "locations['PoliceDistrict']=data_with_location['PoliceDistrict'] # add district infor\n",
    "locations = locations[locations['lat']>1]#get ride of werid data that is close to 0\n",
    "locations = locations[locations['lon']< -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group4 = locations.groupby('PoliceDistrict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save the min/max lat/lon values in each district\n",
    "location = []\n",
    "for i, group in group4:\n",
    "    a1 =((group['lat'].min()+ group['lat'].max())/2, group['lon'].min()) \n",
    "    a2 = ((group['lat'].min()+ group['lat'].max())/2, group['lon'].max())\n",
    "    b1 = (group['lat'].min(),(group['lon'].min()+group['lon'].max())/2)\n",
    "    b2 = (group['lat'].max(),(group['lon'].min()+group['lon'].max())/2)\n",
    "    location.append([a1,a2,b1,b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "988.72006531349064"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from geopy.distance import vincenty\n",
    "from math import pi\n",
    "import numpy as np\n",
    "#calculate an elipse area \n",
    "def calculate_area(loc1, loc2, loc3, loc4):\n",
    "    a = vincenty(loc1, loc2).meters/2000\n",
    "    b = vincenty(loc3, loc4).meters/2000\n",
    "    return pi*a*b\n",
    "areas = []\n",
    "for loc in location:\n",
    "    loc1 = loc[0]\n",
    "    loc2 = loc[1]\n",
    "    loc3 = loc[2]\n",
    "    loc4 = loc[3]\n",
    "    area = calculate_area(loc1, loc2, loc3, loc4)\n",
    "    areas.append(area)\n",
    "np.asarray(area).max() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: The calls are assigned a priority. Some types of calls will receive a greater variety of priorities. To understand which type of call has the most variation in priority, find the type of call whose most common priority is the smallest fraction of all calls of that type. What is that smallest fraction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group5 = data[['Type_', 'Priority']].groupby('Type_') #group priority data by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the highest priority ratio in each group\n",
    "results = []\n",
    "for i, group in group5:\n",
    "    ratio = float(group['Priority'].value_counts().max())/group['Priority'].value_counts().sum() \n",
    "    results.append(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3073611709\n"
     ]
    }
   ],
   "source": [
    "print np.asarray(results).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
